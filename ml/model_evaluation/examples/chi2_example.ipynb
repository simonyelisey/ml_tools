{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2921459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from chi2 import chi2_model_eval, mcnemar_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72cb351",
   "metadata": {},
   "source": [
    "CHI-SQUARED TEST FOR A SINGLE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4a40a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic = 32.884319981094166\n",
      "P-value = 9.780899116984747e-09\n",
      "Alpha = 0.05\n",
      "\n",
      "Model is Not a random guesser (reject H0).\n"
     ]
    }
   ],
   "source": [
    "# model's confusion matrix\n",
    "conf_matrix = [[58,7],\n",
    "               [11,24]]\n",
    "\n",
    "# H0 - variables in contingency table are independent (model is a random guesser)\n",
    "# H1 - variables in contingency table are dependent (model is not a random guesser)\n",
    "\n",
    "# calculation\n",
    "chi2_model_eval(conf_matrix, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6754854d",
   "metadata": {},
   "source": [
    "**CONCLUSION**:\n",
    "\n",
    "We see that chi2 test rejects H0, that means that model predictions and actual values are dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09710b63",
   "metadata": {},
   "source": [
    "COMPARING TWO MODELS USIN THE CHI-SQUARED TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8068faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_1_is_correct</th>\n",
       "      <th>clf_2_is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clf_1_is_correct  clf_2_is_correct\n",
       "0                 1                 0\n",
       "1                 0                 0\n",
       "2                 0                 1\n",
       "3                 0                 0\n",
       "4                 1                 1\n",
       "5                 1                 1\n",
       "6                 1                 1\n",
       "7                 0                 0\n",
       "8                 1                 0\n",
       "9                 1                 1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of two models\n",
    "# 1 - correct prediction\n",
    "# 0 - incorrect prediction\n",
    "\n",
    "models_results = pd.DataFrame({'clf_1_is_correct': [1, 0, 0, 0, 1, 1, 1, 0, 1, 1],\n",
    "                                 'clf_2_is_correct': [0, 0, 1, 0, 1, 1, 1, 0, 0, 1]})\n",
    "models_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3aa91139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unique intersections\n",
    "both_1 = models_results[(models_results['clf_1_is_correct'] == 1) & (models_results['clf_1_is_correct'] == models_results['clf_2_is_correct'])].count()[0]\n",
    "both_0 = models_results[(models_results['clf_1_is_correct'] == 0) & (models_results['clf_1_is_correct'] == models_results['clf_2_is_correct'])].count()[0]\n",
    "clf11_clf20 = models_results[(models_results['clf_1_is_correct'] == 1) & (models_results['clf_2_is_correct'] == 0)].count()[0]\n",
    "clf10_clf21 = models_results[(models_results['clf_1_is_correct'] == 0) & (models_results['clf_2_is_correct'] == 1)].count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1beaeced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf2_correct</th>\n",
       "      <th>clf2_incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clf1_correct</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clf2_incorrect</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                clf2_correct  clf2_incorrect\n",
       "clf1_correct               4               2\n",
       "clf2_incorrect             1               3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create contingency table \n",
    "cont_table = pd.DataFrame({'clf2_correct': [both_1, clf10_clf21],\n",
    "                           'clf2_incorrect': [clf11_clf20, both_0]},\n",
    "                           index=['clf1_correct', 'clf2_incorrect'])\n",
    "cont_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fde84c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar statistic = 0.0\n",
      "P-value = 0.125\n",
      "Alpha = 0.05\n",
      "\n",
      "Same proportions of errors (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "# calculate th test of homogeneity \n",
    "\n",
    "# H0 - classifiers have a similar proportion of errors on the test set\n",
    "# H1 - classifiers have a different proportion of errors on the test set\n",
    "\n",
    "mcnemar_comparison(cont_table, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24541b69",
   "metadata": {},
   "source": [
    "**CONCLUSION**:\n",
    "\n",
    "\n",
    "As we are using the test to compare classifiers, we state that there is no statistically significant difference in the disagreements between the two models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
